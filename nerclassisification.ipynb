{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4a2ccc76ec7d53",
   "metadata": {},
   "source": [
    "# Token Classification (NER) with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b388ab6fdcd3b",
   "metadata": {},
   "source": [
    "## Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "8aab88e4fefffd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:34.721869Z",
     "start_time": "2025-09-07T05:56:31.536654Z"
    }
   },
   "source": [
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA build: 12.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e54b9472651ed610",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:42.165768Z",
     "start_time": "2025-09-07T05:56:34.757974Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tokenizers\n",
    "import seqeval\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, BertTokenizerFast\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gundo\\anaconda3\\envs\\py312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "d3697e7fd0de70d7",
   "metadata": {},
   "source": [
    "## Load the dataset and analyze"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb8d3a0722f64e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:43.425466Z",
     "start_time": "2025-09-07T05:56:42.572155Z"
    }
   },
   "source": [
    "conds=load_dataset(\"conll2003\",trust_remote_code=True)\n",
    "conds\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'conll2003' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "Using the latest cached version of the dataset since conll2003 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'conll2003' at C:\\Users\\gundo\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98 (last modified on Sat Sep  6 17:35:35 2025).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "813c972873ae37dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:43.502070Z",
     "start_time": "2025-09-07T05:56:43.497542Z"
    }
   },
   "source": [
    "conds.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d2c2078e6cb3b575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:43.540867Z",
     "start_time": "2025-09-07T05:56:43.536172Z"
    }
   },
   "source": [
    "conds['train']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7f149c5df3e1adc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:43.591208Z",
     "start_time": "2025-09-07T05:56:43.585472Z"
    }
   },
   "source": [
    "conds['train'].features['ner_tags']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "eb75556b1e7feae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:43.658507Z",
     "start_time": "2025-09-07T05:56:43.653823Z"
    }
   },
   "source": [
    "conds['train'].features['tokens']\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(Value('string'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "7c402040c1deda3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:44.400757Z",
     "start_time": "2025-09-07T05:56:44.395536Z"
    }
   },
   "source": [
    "conds['train'].features['pos_tags']\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3634aa0f9853af0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:44.558659Z",
     "start_time": "2025-09-07T05:56:44.554609Z"
    }
   },
   "source": [
    "conds['train'].description\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "66a651a73dae1b46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.201504Z",
     "start_time": "2025-09-07T05:56:44.578012Z"
    }
   },
   "source": [
    "tokenizer= BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "81c7266fa6c3081e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.222212Z",
     "start_time": "2025-09-07T05:56:45.215022Z"
    }
   },
   "source": [
    "example_text =conds['train'][0]\n",
    "example_text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "1cd99cca17ad508b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.266190Z",
     "start_time": "2025-09-07T05:56:45.256678Z"
    }
   },
   "source": [
    "tokenized_input= tokenizer(example_text['tokens'],is_split_into_words=True)\n",
    "tokenized_input"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "97e4da848fadb9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.290695Z",
     "start_time": "2025-09-07T05:56:45.286036Z"
    }
   },
   "source": [
    "tokens=tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
    "word_ids = tokenized_input.word_ids()\n",
    "word_ids"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "61dc41c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.315664Z",
     "start_time": "2025-09-07T05:56:45.311062Z"
    }
   },
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'eu',\n",
       " 'rejects',\n",
       " 'german',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'british',\n",
       " 'lamb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "f663878959c0b77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.339326Z",
     "start_time": "2025-09-07T05:56:45.334304Z"
    }
   },
   "source": [
    "len(example_text['ner_tags'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "3f95063c879f0724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.363171Z",
     "start_time": "2025-09-07T05:56:45.358895Z"
    }
   },
   "source": [
    "len(tokenized_input['input_ids'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "62a01f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.381731Z",
     "start_time": "2025-09-07T05:56:45.378654Z"
    }
   },
   "source": [
    "#We need to align tokens and labels to get better results and make no room for inconsistency\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "392c787b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.402012Z",
     "start_time": "2025-09-07T05:56:45.396567Z"
    }
   },
   "source": [
    "def tokenize_and_align_labels(example,label_all_tokens=True):\n",
    "    tokenized_input = tokenizer(example['tokens'],truncation=True,is_split_into_words=True)\n",
    "    labels =[]\n",
    "\n",
    "    for i,label in enumerate(example['ner_tags']):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        previous_word_idx=None\n",
    "        label_ids=[]\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx!= previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input['labels']=labels\n",
    "    return tokenized_input\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6cba3b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.416538Z",
     "start_time": "2025-09-07T05:56:45.410370Z"
    }
   },
   "source": [
    "conds['train'][4:5]['ner_tags']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "0259b2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T05:56:45.436171Z",
     "start_time": "2025-09-07T05:56:45.431570Z"
    }
   },
   "source": [
    "q = tokenize_and_align_labels(conds['train'][4:5])\n",
    "print(q)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "2d570b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T06:04:11.363823Z",
     "start_time": "2025-09-07T06:04:11.359822Z"
    }
   },
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]),q['labels'][0]):\n",
    "    print(f\"{token:_<40} {label}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T06:05:31.039102Z",
     "start_time": "2025-09-07T06:05:31.036086Z"
    }
   },
   "cell_type": "code",
   "source": "#if it is 0 it is not recognized by the NER tags and do not have any tags",
   "id": "ae9736e6fc6cdf72",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T06:09:40.988975Z",
     "start_time": "2025-09-07T06:09:40.967725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#fonskiyonumuzu main datasete uyguluyoruz\n",
    "tokenized_dataset = conds.map(tokenize_and_align_labels,batched=True)\n",
    "tokenized_dataset"
   ],
   "id": "e7c2723ffc846c69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T06:07:51.899064Z",
     "start_time": "2025-09-07T06:07:51.895215Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_dataset['train']",
   "id": "7fa24acbea5ae748",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T06:17:22.648604Z",
     "start_time": "2025-09-07T06:17:22.387093Z"
    }
   },
   "cell_type": "code",
   "source": "model=AutoModelForTokenClassification.from_pretrained('bert-base-uncased',num_labels=9)\n",
   "id": "95a5642f8c9771f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4c5edbad57e21fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
