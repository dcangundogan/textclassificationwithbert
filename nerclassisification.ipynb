{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4a2ccc76ec7d53",
   "metadata": {},
   "source": [
    "# Token Classification (NER) with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b388ab6fdcd3b",
   "metadata": {},
   "source": [
    "## Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "8aab88e4fefffd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:38.668688Z",
     "start_time": "2025-09-07T14:54:36.902864Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA build: 12.1\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e54b9472651ed610",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-07T15:31:00.462570Z",
     "start_time": "2025-09-07T15:31:00.460083Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tokenizers\n",
    "import seqeval\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, BertTokenizerFast, pipeline,DataCollatorForTokenClassification\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from evaluate import load"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "id": "d3697e7fd0de70d7",
   "metadata": {},
   "source": [
    "## Load the dataset and analyze"
   ]
  },
  {
   "cell_type": "code",
   "id": "bb8d3a0722f64e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.233487Z",
     "start_time": "2025-09-07T14:54:45.371834Z"
    }
   },
   "source": [
    "conds=load_dataset(\"conll2003\",trust_remote_code=True)\n",
    "conds\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'conll2003' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
      "Using the latest cached version of the dataset since conll2003 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'conll2003' at C:\\Users\\gundo\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98 (last modified on Sun Sep  7 09:06:46 2025).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "813c972873ae37dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.279041Z",
     "start_time": "2025-09-07T14:54:46.274209Z"
    }
   },
   "source": [
    "conds.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d2c2078e6cb3b575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.293352Z",
     "start_time": "2025-09-07T14:54:46.289346Z"
    }
   },
   "source": [
    "conds['train']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "7f149c5df3e1adc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.365791Z",
     "start_time": "2025-09-07T14:54:46.360782Z"
    }
   },
   "source": [
    "conds['train'].features['ner_tags']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "eb75556b1e7feae4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.448702Z",
     "start_time": "2025-09-07T14:54:46.444791Z"
    }
   },
   "source": [
    "conds['train'].features['tokens']\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(Value('string'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "7c402040c1deda3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.493037Z",
     "start_time": "2025-09-07T14:54:46.488039Z"
    }
   },
   "source": [
    "conds['train'].features['pos_tags']\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3634aa0f9853af0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:46.510561Z",
     "start_time": "2025-09-07T14:54:46.506554Z"
    }
   },
   "source": [
    "conds['train'].description\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "66a651a73dae1b46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.134104Z",
     "start_time": "2025-09-07T14:54:46.523299Z"
    }
   },
   "source": [
    "tokenizer= BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "81c7266fa6c3081e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.146231Z",
     "start_time": "2025-09-07T14:54:47.141110Z"
    }
   },
   "source": [
    "example_text =conds['train'][0]\n",
    "example_text"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "1cd99cca17ad508b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.163810Z",
     "start_time": "2025-09-07T14:54:47.158433Z"
    }
   },
   "source": [
    "tokenized_input= tokenizer(example_text['tokens'],is_split_into_words=True)\n",
    "tokenized_input"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "97e4da848fadb9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.177647Z",
     "start_time": "2025-09-07T14:54:47.172939Z"
    }
   },
   "source": [
    "tokens=tokenizer.convert_ids_to_tokens(tokenized_input['input_ids'])\n",
    "word_ids = tokenized_input.word_ids()\n",
    "word_ids"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "61dc41c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.199221Z",
     "start_time": "2025-09-07T14:54:47.194797Z"
    }
   },
   "source": [
    "tokens"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'eu',\n",
       " 'rejects',\n",
       " 'german',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'british',\n",
       " 'lamb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "f663878959c0b77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.223177Z",
     "start_time": "2025-09-07T14:54:47.218866Z"
    }
   },
   "source": [
    "len(example_text['ner_tags'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "3f95063c879f0724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.241313Z",
     "start_time": "2025-09-07T14:54:47.237691Z"
    }
   },
   "source": [
    "len(tokenized_input['input_ids'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "62a01f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.256370Z",
     "start_time": "2025-09-07T14:54:47.253367Z"
    }
   },
   "source": [
    "#We need to align tokens and labels to get better results and make no room for inconsistency\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "392c787b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.269864Z",
     "start_time": "2025-09-07T14:54:47.265473Z"
    }
   },
   "source": [
    "def tokenize_and_align_labels(example,label_all_tokens=True):\n",
    "    tokenized_input = tokenizer(example['tokens'],truncation=True,is_split_into_words=True)\n",
    "    labels =[]\n",
    "\n",
    "    for i,label in enumerate(example['ner_tags']):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        previous_word_idx=None\n",
    "        label_ids=[]\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx!= previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input['labels']=labels\n",
    "    return tokenized_input\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6cba3b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.281372Z",
     "start_time": "2025-09-07T14:54:47.276372Z"
    }
   },
   "source": [
    "conds['train'][4:5]['ner_tags']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "0259b2f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.299999Z",
     "start_time": "2025-09-07T14:54:47.295681Z"
    }
   },
   "source": [
    "q = tokenize_and_align_labels(conds['train'][4:5])\n",
    "print(q)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "2d570b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.323780Z",
     "start_time": "2025-09-07T14:54:47.319695Z"
    }
   },
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q['input_ids'][0]),q['labels'][0]):\n",
    "    print(f\"{token:_<40} {label}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.339595Z",
     "start_time": "2025-09-07T14:54:47.336594Z"
    }
   },
   "cell_type": "code",
   "source": "#if it is 0 it is not recognized by the NER tags and do not have any tags",
   "id": "ae9736e6fc6cdf72",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.429817Z",
     "start_time": "2025-09-07T14:54:47.350967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#fonskiyonumuzu main datasete uyguluyoruz\n",
    "tokenized_dataset = conds.map(tokenize_and_align_labels,batched=True)\n",
    "tokenized_dataset"
   ],
   "id": "e7c2723ffc846c69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.439037Z",
     "start_time": "2025-09-07T14:54:47.435099Z"
    }
   },
   "cell_type": "code",
   "source": "tokenized_dataset['train']",
   "id": "7fa24acbea5ae748",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 14041\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:54:47.776761Z",
     "start_time": "2025-09-07T14:54:47.477249Z"
    }
   },
   "cell_type": "code",
   "source": "model=AutoModelForTokenClassification.from_pretrained('bert-base-uncased',num_labels=9)\n",
   "id": "95a5642f8c9771f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:59:02.070235Z",
     "start_time": "2025-09-07T14:59:02.067340Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import TrainingArguments,Trainer ,DataCollatorForTokenClassification\n",
   "id": "b4c5edbad57e21fa",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:59:03.641817Z",
     "start_time": "2025-09-07T14:59:03.580812Z"
    }
   },
   "cell_type": "code",
   "source": "args=TrainingArguments('test-ner',eval_strategy='epoch',learning_rate=2e-5,per_device_train_batch_size=16,per_device_eval_batch_size=16,num_train_epochs=1,weight_decay=0.01)",
   "id": "48330dc36ad57b73",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T14:59:31.086326Z",
     "start_time": "2025-09-07T14:59:31.084340Z"
    }
   },
   "cell_type": "code",
   "source": "data_collator = DataCollatorForTokenClassification(tokenizer)",
   "id": "7f2309f8cded421b",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:02:27.435630Z",
     "start_time": "2025-09-07T15:02:25.837374Z"
    }
   },
   "cell_type": "code",
   "source": "metric = load('seqeval')",
   "id": "69f6a53628616a88",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:02:48.995102Z",
     "start_time": "2025-09-07T15:02:48.991804Z"
    }
   },
   "cell_type": "code",
   "source": "example=conds['train'][0]",
   "id": "8416c2c07ae6ebc8",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:03:33.025428Z",
     "start_time": "2025-09-07T15:03:33.021868Z"
    }
   },
   "cell_type": "code",
   "source": "label_list = conds['train'].features['ner_tags'].feature.names",
   "id": "a263a7f1ad35d837",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:03:38.339487Z",
     "start_time": "2025-09-07T15:03:38.336488Z"
    }
   },
   "cell_type": "code",
   "source": "label_list\n",
   "id": "50417679167f9274",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:04:25.050827Z",
     "start_time": "2025-09-07T15:04:25.046920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = [label_list[i] for i in example['ner_tags']]\n",
    "labels"
   ],
   "id": "dfca5cbe592145b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:08:35.234888Z",
     "start_time": "2025-09-07T15:08:35.223411Z"
    }
   },
   "cell_type": "code",
   "source": "metric.compute(predictions=[labels],references=[labels])",
   "id": "2cfbf23502f7d676",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(2)},\n",
       " 'ORG': {'precision': np.float64(1.0),\n",
       "  'recall': np.float64(1.0),\n",
       "  'f1': np.float64(1.0),\n",
       "  'number': np.int64(1)},\n",
       " 'overall_precision': np.float64(1.0),\n",
       " 'overall_recall': np.float64(1.0),\n",
       " 'overall_f1': np.float64(1.0),\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:25:19.257944Z",
     "start_time": "2025-09-07T15:25:19.253673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Değerlendirme metriği\n",
    "# 2) label_list zaten var:\n",
    "# label_list = conds['train'].features['ner_tags'].feature.names\n",
    "\n",
    "# 3) compute_metrics: seqeval \"sequence of sequences\" ister\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds                      # (batch, seq_len, num_labels), (batch, seq_len)\n",
    "    preds = np.argmax(logits, axis=-1)               # (batch, seq_len)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for p, l in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for p, l in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\":    results[\"overall_recall\"],\n",
    "        \"f1\":        results[\"overall_f1\"],\n",
    "        \"accuracy\":  results[\"overall_accuracy\"],\n",
    "    }\n"
   ],
   "id": "a99956bda4d84c77",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:26:24.255520Z",
     "start_time": "2025-09-07T15:26:24.248303Z"
    }
   },
   "cell_type": "code",
   "source": "trainer = Trainer(model=model,args=args,train_dataset=tokenized_dataset['train'],eval_dataset=tokenized_dataset['validation'],tokenizer=tokenizer,data_collator=data_collator,compute_metrics=compute_metrics)",
   "id": "863e0344fec66a4b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gundo\\AppData\\Local\\Temp\\ipykernel_19476\\2963141010.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model,args=args,train_dataset=tokenized_dataset['train'],eval_dataset=tokenized_dataset['validation'],tokenizer=tokenizer,data_collator=data_collator,compute_metrics=compute_metrics)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:27:57.889074Z",
     "start_time": "2025-09-07T15:26:27.424689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "\n",
    "model.save_pretrained('ner_model')\n",
    "tokenizer.save_pretrained('tokenizer')"
   ],
   "id": "3e6f088c88723375",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [878/878 01:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.069589</td>\n",
       "      <td>0.904511</td>\n",
       "      <td>0.921915</td>\n",
       "      <td>0.913130</td>\n",
       "      <td>0.980809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:27:57.914476Z",
     "start_time": "2025-09-07T15:27:57.910472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id2label = {str(i):label for i,label in  enumerate(label_list)}\n",
    "\n",
    "label2id = {\n",
    "    label: str(i)  for i,label in enumerate(label_list)\n",
    "}"
   ],
   "id": "16ef98dbc7611d51",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:28:06.734064Z",
     "start_time": "2025-09-07T15:28:06.730837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "config= json.load(open('ner_model/config.json'))"
   ],
   "id": "dd87debadca1364",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:28:48.466766Z",
     "start_time": "2025-09-07T15:28:48.399833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config['id2label']= id2label\n",
    "config['label2id']==label2id\n",
    "json.dump(config,open('ner_model/config.json','w'))\n",
    "\n",
    "model_fine_tuned= AutoModelForTokenClassification.from_pretrained('ner_model')"
   ],
   "id": "d751e265610df3dd",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T15:37:40.215645Z",
     "start_time": "2025-09-07T15:37:40.132049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = pipeline('ner',model=model_fine_tuned,tokenizer=tokenizer)\n",
    "text=\"Bill Gates is the Founder of Microsoft.\"\n",
    "ner_results=nlp(text)\n",
    "print(ner_results)"
   ],
   "id": "4b430661727bfaec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': np.float32(0.9666577), 'index': 1, 'word': 'bill', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': np.float32(0.9428921), 'index': 2, 'word': 'gates', 'start': 5, 'end': 10}, {'entity': 'B-ORG', 'score': np.float32(0.9608258), 'index': 7, 'word': 'microsoft', 'start': 29, 'end': 38}]\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c68291acbef019fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
